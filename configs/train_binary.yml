# ====================
# Run Configuration
# ====================
run:
  name: all_langs_pos_weight
  runs_dir: ./runs/binary
  resume:
    enable: 0
    ckpt_name: null

# ====================
# Training Parameters
# ====================
train:
  pretrain:
    steps: 50000
    lr: 0.00002 #2e-5
    lr_warmup: 0.05
  finetune:
    steps: 0
    lr: 0.000004 #4e-6 = 2e-5 / 5
    lr_warmup: 0.10
  pos_weight:
    enable: 1
    weight: 32.83


# ====================
# Model Configuration
# ====================
model:
  backbone: microsoft/mdeberta-v3-base
  max_length: 256
  threshold: 0.5

# ====================
# Dataset Configuration
# ====================
data:
  finetune_tgt_lang: null
  train_manifest: ./datasets/processed/train/manifest.json
  valid_manifest: ./datasets/processed/valid/manifest.json
  batch_size: 16
  alpha: 0.5

# ====================
# Logging Configuration
# ====================
logging:

  wandb:
    enable: true
    save_ckpt: 0

  loss_steps: 10
  valid_steps:
    pretrain: 5000
    finetune: 1000

  ckpt_steps:
    pretrain: 12500
    finetune: 2500
